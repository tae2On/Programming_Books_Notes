<h2>📌 PART 4. 분류</h2>

**전체 코드 및 결과를 확인하시려면 [여기](https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/%EB%B6%84%EB%A5%98.ipynb "전체 코드 보기") 를 클릭하세요.<br> 각 예제 코드와 그 결과를 자세히 확인하실 수 있습니다.**

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/1.%20%EB%B6%84%EB%A5%98(Classification)%EC%9D%98%20%EA%B0%9C%EC%9A%94.md">1. 분류(Classification)의 개요</a></h3>

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/2.%20%EA%B2%B0%EC%A0%95%20%ED%8A%B8%EB%A6%AC.md">2. 결정 트리</a></h3>

*결정 트리 모델의 특징, 결정 트리 파라미터, 결정 트리 모델의 시각화, 결정 트리 과적합(Overfitting)*

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/3.%20%EC%95%99%EC%83%81%EB%B8%94%20%ED%95%99%EC%8A%B5.md">3. 앙상블 학습</a></h3>

*앙상블 학습 개요, 보팅 유형, 보팅 분류기(Voting Classifier)*

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/4.%20%EB%9E%9C%EB%8D%A4%20%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.md">4. 랜덤 포레스트</a></h3>

*랜덤 포레스트의 개요 및 실습, 랜덤 포레스트 하이퍼 파라미터 및 튜닝*

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/5.%20GBM(Gradient%20Boosting%20Machine).md">5. GBM(Gradient Boosting Machine)</a></h3>

*GBM의 개요 및 실습, GBM 하이퍼 파라미터 및 튜닝*

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/6.%20XGBoost(eXtra%20Gradient%20Boost).md">6. XGBoost(eXtra Gradient Boost)</a></h3>

*XGBoost 개요, XGBoost 설치하기, 파이썬 래퍼 XGBoost 하이퍼 파라미터, 파이썬 래퍼 XGBoost 적용, 사이킷런 래퍼 XGBoost의 개요 및 적용* 

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/7.%20LightGBM.md">7. LightGBM</a></h3>

*LightGBM 설치, LightGBM 하이퍼 파라미터, 하이퍼 파라미터 튜닝 방안, 파이썬 래퍼 LightGBM과 사이킷런 래퍼 XGBoost, LightGBM 하이퍼 파라미터 비교, LightGBM 적용*

<h3>8. 베이지안 최적화 기반의 HyperOpt를 이용한 하이퍼 파라미터 튜닝</h3>

*베이지안 최적화 개요, HyperOpt 사용하기, HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화*

<h3>9. 분류 실습 - 캐글 산탄데르 고객 만족 예측</h3>

*데이터 전처리, XGBoost 모델 학습과 하이퍼 파라미터 튜닝, LightGBM 모델 학습과 하이퍼 파라미터 튜닝*

<h3><a href="https://github.com/tae2On/Technical_Books_Notes/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%20%EC%99%84%EB%B2%BD%20%EA%B0%80%EC%9D%B4%EB%93%9C/04.%20%EB%B6%84%EB%A5%98/%EC%BA%90%EA%B8%80%20%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C%20%EC%82%AC%EA%B8%B0%20%EA%B2%80%EC%B6%9C.ipynb">10. 분류 실습 - 캐글 신용카드 사기 검출</a></h3>

*언더 샘플링과 오버 샘플링의 이해, 데이터 일차 가공 및 모델 학습/예측/평가, 데이터 분포도 변환 후 모델 학습/예측/평가, 이상치 데이터 제거 후 모델 학습/예측/평가, SMOTE 오버 샘플링 적용 후 모델 학습/예측/평가*

<h3>11. 스태킹 앙상블</h3>

*기본 스태킹 모델, CV 세트 기반의 스태킹*
