<h2>📌 PART 2. 사이킷런으로 시작하는 머신러닝</h2>
<h3>✓ Model Selection 모듈 소개</h3>

**사이킷런의 model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공한다.**

<h4>학습/테스트 데이터 세트 분리 - train_test_split()</h4>
사이킷런의 train_test_split()를 통해 원본 데이터 세트에서 학습 및 테스트 데이터 세트를 쉽게 분리할 수 있다.<br>

<h4>교차 검증</h4>
학습 데이터와 테스트 데이터를 사용해 모델을 평가하는 방법은 과적합의 위험이 있다. 과적합은 모델이 학습 데이터에만 최적화되어 다른 데이터에서 성능이 저하되는 문제를 의미한다. 고정된 학습 데이터와 테스트 데이터로 평가하면 모델이 테스트 데이터에만 과적합될 수 있다. <br>
<br>
교차 검증은 이러한 데이터 편중을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다.<br>

<h4>K 폴드 교차 검증</h4>
K 폴드 교차 검증은 가장 보편적으로 사용된는 교차 검증 기법으로 K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다. <br>
<br>
교차 검증은 이러한 데이터 편중을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다.<br>

<h4>Stratified K 폴드</h4>
Stratified K 폴드는 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식이다. 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 말한다. <br>
<br>
Stratified K 폴드는 K 폴드가 레이블 분포를 적절히 반영하지 못하는 문제를 해결하며, 원본 데이터의 레이블 분포를 고려하여 학습과 검증 데이터 세트를 동일한 분포로 분배한다.

<h4>교차 검증을 보다 간편하게 - cross_val_score()</h4>
사이킷런은 교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API를 제공한다. 대표적인 것이 cross_val_score()이며 이 함수는 KFold와 같은 교차 검증을 자동으로 처리해준다.<br>
<br>
cross_val_score()는 cvv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결과값을 배열로 반환한다. 그리고 일반적으로 이를 평균해 평가 수치로 사용한다. cross_val_score() API는 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation)시켜주므로 간단하게 교차 검증을 수행할 수 있다.<br>

<h4>GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에</h4>
사이킷런의 GridSearchCV는 교차 검증과 하이퍼 파라미터 튜닝을 동시에 수행할 수 있는 API이다. GridSearchCV는 하이퍼 파라미터의 격자(grid)를 생성하여 순차적으로 테스트하며 최적의 파라미터를 도출한다.<br>
<br>
이 과정에서 데이터 세트를 자동으로 학습/테스트 세트로 분할하고, 하이퍼 파라미터 그리드에 명시된 모든 조합을 평가하여 최적의 파라미터를 찾는다. GridSearchCV는 다양한 하이퍼 파라미터를 테스트하는 편리한 방법을 제공하지만, 순차적인 테스트로 인해 수행 시간이 길어질 수 있다.<br>
